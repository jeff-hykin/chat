"$schema" = 'https://raw.githubusercontent.com/load1n9/chat/refs/heads/main/config-schema.json'

[config]
model = "onnx-community/Llama-3.2-1B-Instruct" # Model to use
system = [
  "You are an assistant designed to help with any questions the user might have."
] # System prompts
max_new_tokens = 128 # Maximum number of tokens to generate
max_length = 20 # Maximum length of the response
temperature = 1.0 # Temperature for sampling
top_p = 1.0 # Top-p for sampling
repetition_penalty = 1.2 # Repetition penalty
